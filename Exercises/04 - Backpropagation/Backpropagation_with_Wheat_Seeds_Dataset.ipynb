{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Backpropagation_with_Wheat_Seeds_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "oNZw1pd3zPIx"
      },
      "source": [
        "#@title [Candidature form]\n",
        "\n",
        "Name = '' #@param {type: \"string\"}\n",
        "Matriculation_number = '' #@param {type:\"string\"}\n",
        "Faculty = ''  #@param {type: \"string\"}\n",
        "Course = '' #@param {type:\"string\"}\n",
        "Current_semester = \"\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"] {allow-input: true}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lLAT0jdzVi2"
      },
      "source": [
        "# Deep Neural Network with Backpropagation\n",
        "## Machine Learning Project - 04 \n",
        "This project is created and adapted as a Jupyter notebook for [**MME 26849: \"Fundamentals of Deep Learning and TinyML\"**](https://felix.hs-furtwangen.de/url/RepositoryEntry/4020862983) by the course instructors [Marcus Rüb](https://linkedin.com/in/marcus-rüb-3b07071b2) and [Ajay Krishna](https://linkedin.com/in/ajay-krishna-2031a5119).\n",
        "\n",
        "## Resouces\n",
        "Slide from lecture:\n",
        "[04 - Neural Networks](https://github.com/r1marcus/Fundamentals-of-Deep-Learning-HFU/blob/main/Slides/04%20-%20neural%20networks/Neuralnetworks.pptx)\n",
        "\n",
        "## Goal of the project\n",
        "Implementation of a neural network with backpropagation to extract, examine, analyze, train, and predict on Wheat-Seeds dataset. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFWcOOhIzpuY"
      },
      "source": [
        "## Import libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyWEOJUky2ds"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg4ZkNe3z1el"
      },
      "source": [
        "## Functions: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa9bxoXsy2dy"
      },
      "source": [
        "#activation function (sigmoid)\n",
        "def sigmoid(x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_prime(x):\n",
        "    return sigmoid(x)*(1.0 - sigmoid(x))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ2gkz8Ny2dz"
      },
      "source": [
        "class NeuralNetwork(object):\n",
        "    \n",
        "    def __init__(self, architecture):\n",
        "        #architecture - numpy array with ith element representing the number of neurons in the ith layer.\n",
        "        \n",
        "        #Initialize the network architecture\n",
        "        self.L = architecture.size - 1 #The index of the last layer L\n",
        "        self.n = architecture #n stores the number of neurons in each layer\n",
        "        self.input_size = self.n[0] #input_size is the number of neurons in the first layer\n",
        "        self.output_size = self.n[self.L] #output_size is the number of neurons in the last layer\n",
        "        \n",
        "        #Parameters will store the network parameters, i.e. the weights and biases\n",
        "        self.parameters = {}\n",
        "        \n",
        "        #Initialize the network weights and biases:\n",
        "        for i in range (1, self.L + 1): \n",
        "            #Initialize weights to small random values\n",
        "            self.parameters['W' + str(i)] = np.random.randn(self.n[i], self.n[i - 1]) * 0.01\n",
        "            \n",
        "            #Initialize rest of the parameters to 1\n",
        "            self.parameters['b' + str(i)] = np.ones((self.n[i], 1))\n",
        "            self.parameters['z' + str(i)] = np.ones((self.n[i], 1))\n",
        "            self.parameters['a' + str(i)] = np.ones((self.n[i], 1))\n",
        "        \n",
        "        #As we started the loop from 1, we haven't initialized a[0]:\n",
        "        self.parameters['a0'] = np.ones((self.n[i], 1))\n",
        "        \n",
        "        #Initialize the cost:\n",
        "        self.parameters['C'] = 1\n",
        "        \n",
        "        #Create a dictionary for storing the derivatives:\n",
        "        self.derivatives = {}\n",
        "        \n",
        "        #Learning rate\n",
        "        self.alpha = 0.01\n",
        "            \n",
        "    def forward_propagate(self, X):\n",
        "        #Note that X here, is just one training example\n",
        "        self.parameters['a0'] = X\n",
        "        \n",
        "        #Calculate the activations for every layer l\n",
        "        for l in range(1, self.L + 1):\n",
        "            self.parameters['z' + str(l)] = np.add(np.dot(self.parameters['W' + str(l)], self.parameters['a' + str(l - 1)]), self.parameters['b' + str(l)])\n",
        "            self.parameters['a' + str(l)] = sigmoid(self.parameters['z' + str(l)])\n",
        "        \n",
        "    def compute_cost(self, y):\n",
        "        self.parameters['C'] = -(y*np.log(self.parameters['a' + str(self.L)]) + (1-y)*np.log( 1 - self.parameters['a' + str(self.L)]))\n",
        "    \n",
        "    def compute_derivatives(self, y):\n",
        "        #Partial derivatives of the cost function with respect to z[L], W[L] and b[L]:        \n",
        "        #dzL\n",
        "        self.derivatives['dz' + str(self.L)] = self.parameters['a' + str(self.L)] - y\n",
        "        #dWL\n",
        "        self.derivatives['dW' + str(self.L)] = np.dot(self.derivatives['dz' + str(self.L)], np.transpose(self.parameters['a' + str(self.L - 1)]))\n",
        "        #dbL\n",
        "        self.derivatives['db' + str(self.L)] = self.derivatives['dz' + str(self.L)]\n",
        "\n",
        "        #Partial derivatives of the cost function with respect to z[l], W[l] and b[l]\n",
        "        for l in range(self.L-1, 0, -1):\n",
        "            self.derivatives['dz' + str(l)] = np.dot(np.transpose(self.parameters['W' + str(l + 1)]), self.derivatives['dz' + str(l + 1)])*sigmoid_prime(self.parameters['z' + str(l)])\n",
        "            self.derivatives['dW' + str(l)] = np.dot(self.derivatives['dz' + str(l)], np.transpose(self.parameters['a' + str(l - 1)]))\n",
        "            self.derivatives['db' + str(l)] = self.derivatives['dz' + str(l)]\n",
        "            \n",
        "    def update_parameters(self):\n",
        "        for l in range(1, self.L+1):\n",
        "            self.parameters['W' + str(l)] -= self.alpha*self.derivatives['dW' + str(l)]\n",
        "            self.parameters['b' + str(l)] -= self.alpha*self.derivatives['db' + str(l)]\n",
        "        \n",
        "    def predict(self, x):\n",
        "        self.forward_propagate(x)\n",
        "        \n",
        "        #self.parameters['a0'] = X\n",
        "        \n",
        "        #Calculate the activations for every layer l\n",
        "        #for i in range(1, self.L + 1):\n",
        "         #   self.parameters['z' + str(i)] = np.add(np.dot(self.parameters['W' + str(i)], self.parameters['a' + str(i - 1)]), self.parameters['b' + str(i)])\n",
        "          #  self.parameters['a' + str(i)] = sigmoid(self.parameters['z' + str(i)])\n",
        "\n",
        "        return self.parameters['a' + str(self.L)]\n",
        "        \n",
        "    def fit(self, X, Y, num_iter):\n",
        "        for iter in range(0, num_iter):\n",
        "            c = 0\n",
        "            acc = 0\n",
        "            n_c = 0\n",
        "            for i in range(0, X.shape[0]):\n",
        "              x = X[i].reshape((X[i].size, 1))\n",
        "              y = Y[i]\n",
        "              self.forward_propagate(x)\n",
        "              self.compute_cost(y)\n",
        "              c += self.parameters['C'] \n",
        "              y_pred = self.predict(x)\n",
        "              y_pred = (y_pred > 0.5)\n",
        "              if y_pred == y:\n",
        "                  n_c += 1\n",
        "              self.compute_derivatives(y)\n",
        "              self.update_parameters()\n",
        "            \n",
        "            c = c/X.shape[0]\n",
        "            acc = (n_c/X.shape[0])*100\n",
        "            print('Iteration: ', iter)\n",
        "            print(\"Cost: \", c)\n",
        "            print(\"Accuracy:\", acc)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T0Pud7A0L3C"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfbGroR70QCA"
      },
      "source": [
        "The Iris data for our exercise can be found at: https://drive.google.com/file/d/1UGujQZnz65UL2GHucPaNUwRoH4y9oEdO/view?usp=sharing\n",
        "\n",
        "\n",
        "Steps for loading data:\n",
        "\n",
        "    1. Press the above link \"https://drive.google.com/file/d/1UGujQZnz65UL2GHucPaNUwRoH4y9oEdO/view?usp=sharing\"\n",
        "    2. Unzip/extract the data to your local machine (It should be .csv file).\n",
        "    3. Press the folder icon on the left in the Colab window and upload \"wheat-seeds-binary.csv\" from your local machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "sb7PGPRWy2d0",
        "outputId": "aae8efd3-f7a4-464e-a187-4199fe1c466d"
      },
      "source": [
        "dataset = pd.read_csv('wheat-seeds-binary.csv')\n",
        "dataset"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Perimeter</th>\n",
              "      <th>Compactness</th>\n",
              "      <th>Length of Kernel</th>\n",
              "      <th>Width of Kernel</th>\n",
              "      <th>Asymmetry Coefficient</th>\n",
              "      <th>Length of Kernel Groove</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.26</td>\n",
              "      <td>14.84</td>\n",
              "      <td>0.8710</td>\n",
              "      <td>5.763</td>\n",
              "      <td>3.312</td>\n",
              "      <td>2.221</td>\n",
              "      <td>5.220</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.88</td>\n",
              "      <td>14.57</td>\n",
              "      <td>0.8811</td>\n",
              "      <td>5.554</td>\n",
              "      <td>3.333</td>\n",
              "      <td>1.018</td>\n",
              "      <td>4.956</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.29</td>\n",
              "      <td>14.09</td>\n",
              "      <td>0.9050</td>\n",
              "      <td>5.291</td>\n",
              "      <td>3.337</td>\n",
              "      <td>2.699</td>\n",
              "      <td>4.825</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.84</td>\n",
              "      <td>13.94</td>\n",
              "      <td>0.8955</td>\n",
              "      <td>5.324</td>\n",
              "      <td>3.379</td>\n",
              "      <td>2.259</td>\n",
              "      <td>4.805</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16.14</td>\n",
              "      <td>14.99</td>\n",
              "      <td>0.9034</td>\n",
              "      <td>5.658</td>\n",
              "      <td>3.562</td>\n",
              "      <td>1.355</td>\n",
              "      <td>5.175</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>15.38</td>\n",
              "      <td>14.66</td>\n",
              "      <td>0.8990</td>\n",
              "      <td>5.477</td>\n",
              "      <td>3.465</td>\n",
              "      <td>3.600</td>\n",
              "      <td>5.439</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>17.36</td>\n",
              "      <td>15.76</td>\n",
              "      <td>0.8785</td>\n",
              "      <td>6.145</td>\n",
              "      <td>3.574</td>\n",
              "      <td>3.526</td>\n",
              "      <td>5.971</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>15.57</td>\n",
              "      <td>15.15</td>\n",
              "      <td>0.8527</td>\n",
              "      <td>5.920</td>\n",
              "      <td>3.231</td>\n",
              "      <td>2.640</td>\n",
              "      <td>5.879</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>15.60</td>\n",
              "      <td>15.11</td>\n",
              "      <td>0.8580</td>\n",
              "      <td>5.832</td>\n",
              "      <td>3.286</td>\n",
              "      <td>2.725</td>\n",
              "      <td>5.752</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>16.23</td>\n",
              "      <td>15.18</td>\n",
              "      <td>0.8850</td>\n",
              "      <td>5.872</td>\n",
              "      <td>3.472</td>\n",
              "      <td>3.769</td>\n",
              "      <td>5.922</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>140 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Area  Perimeter  ...  Length of Kernel Groove  Class\n",
              "0    15.26      14.84  ...                    5.220      1\n",
              "1    14.88      14.57  ...                    4.956      1\n",
              "2    14.29      14.09  ...                    4.825      1\n",
              "3    13.84      13.94  ...                    4.805      1\n",
              "4    16.14      14.99  ...                    5.175      1\n",
              "..     ...        ...  ...                      ...    ...\n",
              "135  15.38      14.66  ...                    5.439      2\n",
              "136  17.36      15.76  ...                    5.971      2\n",
              "137  15.57      15.15  ...                    5.879      2\n",
              "138  15.60      15.11  ...                    5.752      2\n",
              "139  16.23      15.18  ...                    5.922      2\n",
              "\n",
              "[140 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGIzE68Z1_5Z"
      },
      "source": [
        "Shuffling the labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "yVGt7F8cy2d1",
        "outputId": "018f8d64-31ac-464a-cd1a-1e777585bf21"
      },
      "source": [
        "shuffled_dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "shuffled_dataset['Class'] = shuffled_dataset['Class'] - 1\n",
        "\n",
        "shuffled_dataset"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Perimeter</th>\n",
              "      <th>Compactness</th>\n",
              "      <th>Length of Kernel</th>\n",
              "      <th>Width of Kernel</th>\n",
              "      <th>Asymmetry Coefficient</th>\n",
              "      <th>Length of Kernel Groove</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.11</td>\n",
              "      <td>14.18</td>\n",
              "      <td>0.8820</td>\n",
              "      <td>5.541</td>\n",
              "      <td>3.221</td>\n",
              "      <td>2.754</td>\n",
              "      <td>5.038</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.54</td>\n",
              "      <td>13.85</td>\n",
              "      <td>0.8871</td>\n",
              "      <td>5.348</td>\n",
              "      <td>3.156</td>\n",
              "      <td>2.587</td>\n",
              "      <td>5.178</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17.12</td>\n",
              "      <td>15.55</td>\n",
              "      <td>0.8892</td>\n",
              "      <td>5.850</td>\n",
              "      <td>3.566</td>\n",
              "      <td>2.858</td>\n",
              "      <td>5.746</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19.57</td>\n",
              "      <td>16.74</td>\n",
              "      <td>0.8779</td>\n",
              "      <td>6.384</td>\n",
              "      <td>3.772</td>\n",
              "      <td>1.472</td>\n",
              "      <td>6.273</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.02</td>\n",
              "      <td>13.76</td>\n",
              "      <td>0.8641</td>\n",
              "      <td>5.395</td>\n",
              "      <td>3.026</td>\n",
              "      <td>3.373</td>\n",
              "      <td>4.825</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>18.95</td>\n",
              "      <td>16.42</td>\n",
              "      <td>0.8829</td>\n",
              "      <td>6.248</td>\n",
              "      <td>3.755</td>\n",
              "      <td>3.368</td>\n",
              "      <td>6.148</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>17.63</td>\n",
              "      <td>15.86</td>\n",
              "      <td>0.8800</td>\n",
              "      <td>6.033</td>\n",
              "      <td>3.573</td>\n",
              "      <td>3.747</td>\n",
              "      <td>5.929</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>14.11</td>\n",
              "      <td>14.26</td>\n",
              "      <td>0.8722</td>\n",
              "      <td>5.520</td>\n",
              "      <td>3.168</td>\n",
              "      <td>2.688</td>\n",
              "      <td>5.219</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>13.74</td>\n",
              "      <td>14.05</td>\n",
              "      <td>0.8744</td>\n",
              "      <td>5.482</td>\n",
              "      <td>3.114</td>\n",
              "      <td>2.932</td>\n",
              "      <td>4.825</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>18.88</td>\n",
              "      <td>16.26</td>\n",
              "      <td>0.8969</td>\n",
              "      <td>6.084</td>\n",
              "      <td>3.764</td>\n",
              "      <td>1.649</td>\n",
              "      <td>6.109</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>140 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Area  Perimeter  ...  Length of Kernel Groove  Class\n",
              "0    14.11      14.18  ...                    5.038      0\n",
              "1    13.54      13.85  ...                    5.178      0\n",
              "2    17.12      15.55  ...                    5.746      1\n",
              "3    19.57      16.74  ...                    6.273      1\n",
              "4    13.02      13.76  ...                    4.825      0\n",
              "..     ...        ...  ...                      ...    ...\n",
              "135  18.95      16.42  ...                    6.148      1\n",
              "136  17.63      15.86  ...                    5.929      1\n",
              "137  14.11      14.26  ...                    5.219      0\n",
              "138  13.74      14.05  ...                    4.825      0\n",
              "139  18.88      16.26  ...                    6.109      1\n",
              "\n",
              "[140 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVqRyX4Ty2d1",
        "outputId": "3b617bc8-0aea-48bf-9120-7868e46b01cc"
      },
      "source": [
        "X = shuffled_dataset.iloc[:, 0:-1].values\n",
        "print(X)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[14.11   14.18    0.882   5.541   3.221   2.754   5.038 ]\n",
            " [13.54   13.85    0.8871  5.348   3.156   2.587   5.178 ]\n",
            " [17.12   15.55    0.8892  5.85    3.566   2.858   5.746 ]\n",
            " [19.57   16.74    0.8779  6.384   3.772   1.472   6.273 ]\n",
            " [13.02   13.76    0.8641  5.395   3.026   3.373   4.825 ]\n",
            " [16.87   15.65    0.8648  6.139   3.463   3.696   5.967 ]\n",
            " [20.2    16.89    0.8894  6.285   3.864   5.173   6.187 ]\n",
            " [12.74   13.67    0.8564  5.395   2.956   2.504   4.869 ]\n",
            " [15.36   14.76    0.8861  5.701   3.393   1.367   5.132 ]\n",
            " [18.89   16.23    0.9008  6.227   3.769   3.639   5.966 ]\n",
            " [14.28   14.17    0.8944  5.397   3.298   6.685   5.001 ]\n",
            " [18.76   16.2     0.8984  6.172   3.796   3.12    6.053 ]\n",
            " [14.09   14.41    0.8529  5.717   3.186   3.92    5.299 ]\n",
            " [14.16   14.4     0.8584  5.658   3.129   3.072   5.176 ]\n",
            " [17.36   15.76    0.8785  6.145   3.574   3.526   5.971 ]\n",
            " [11.42   12.86    0.8683  5.008   2.85    2.7     4.607 ]\n",
            " [20.24   16.91    0.8897  6.315   3.962   5.901   6.188 ]\n",
            " [17.26   15.73    0.8763  5.978   3.594   4.539   5.791 ]\n",
            " [14.69   14.49    0.8799  5.563   3.259   3.586   5.219 ]\n",
            " [12.11   13.47    0.8392  5.159   3.032   1.502   4.519 ]\n",
            " [13.16   13.55    0.9009  5.138   3.201   2.461   4.783 ]\n",
            " [16.41   15.25    0.8866  5.718   3.525   4.217   5.618 ]\n",
            " [16.77   15.62    0.8638  5.927   3.438   4.92    5.795 ]\n",
            " [18.94   16.32    0.8942  6.144   3.825   2.908   5.949 ]\n",
            " [14.86   14.67    0.8676  5.678   3.258   2.129   5.351 ]\n",
            " [16.14   14.99    0.9034  5.658   3.562   1.355   5.175 ]\n",
            " [16.82   15.51    0.8786  6.017   3.486   4.004   5.841 ]\n",
            " [15.6    15.11    0.858   5.832   3.286   2.725   5.752 ]\n",
            " [18.3    15.89    0.9108  5.979   3.755   2.837   5.962 ]\n",
            " [12.36   13.19    0.8923  5.076   3.042   3.22    4.605 ]\n",
            " [18.17   16.26    0.8637  6.271   3.512   2.853   6.273 ]\n",
            " [14.8    14.52    0.8823  5.656   3.288   3.112   5.309 ]\n",
            " [15.69   14.75    0.9058  5.527   3.514   1.599   5.046 ]\n",
            " [11.23   12.63    0.884   4.902   2.879   2.269   4.703 ]\n",
            " [21.18   17.21    0.8989  6.573   4.033   5.78    6.231 ]\n",
            " [15.03   14.77    0.8658  5.702   3.212   1.933   5.439 ]\n",
            " [18.98   16.66    0.859   6.549   3.67    3.691   6.498 ]\n",
            " [14.38   14.21    0.8951  5.386   3.312   2.462   4.956 ]\n",
            " [20.1    16.99    0.8746  6.581   3.785   1.955   6.449 ]\n",
            " [12.72   13.57    0.8686  5.226   3.049   4.102   4.914 ]\n",
            " [16.19   15.16    0.8849  5.833   3.421   0.903   5.307 ]\n",
            " [18.36   16.52    0.8452  6.666   3.485   4.933   6.448 ]\n",
            " [19.46   16.5     0.8985  6.113   3.892   4.308   6.009 ]\n",
            " [15.5    14.86    0.882   5.877   3.396   4.711   5.528 ]\n",
            " [14.59   14.28    0.8993  5.351   3.333   4.185   4.781 ]\n",
            " [16.12   15.      0.9     5.709   3.485   2.27    5.443 ]\n",
            " [14.43   14.4     0.8751  5.585   3.272   3.975   5.144 ]\n",
            " [18.83   16.29    0.8917  6.037   3.786   2.553   5.879 ]\n",
            " [16.23   15.18    0.885   5.872   3.472   3.769   5.922 ]\n",
            " [13.99   13.83    0.9183  5.119   3.383   5.234   4.781 ]\n",
            " [16.63   15.46    0.8747  6.053   3.465   2.04    5.877 ]\n",
            " [19.31   16.59    0.8815  6.341   3.81    3.477   6.238 ]\n",
            " [13.94   14.17    0.8728  5.585   3.15    2.124   5.012 ]\n",
            " [19.38   16.72    0.8716  6.303   3.791   3.678   5.965 ]\n",
            " [14.79   14.52    0.8819  5.545   3.291   2.704   5.111 ]\n",
            " [18.96   16.2     0.9077  6.051   3.897   4.334   5.75  ]\n",
            " [15.26   14.85    0.8696  5.714   3.242   4.543   5.314 ]\n",
            " [15.99   14.89    0.9064  5.363   3.582   3.336   5.144 ]\n",
            " [18.43   15.97    0.9077  5.98    3.771   2.984   5.905 ]\n",
            " [18.27   16.09    0.887   6.173   3.651   2.443   6.197 ]\n",
            " [19.18   16.63    0.8717  6.369   3.681   3.357   6.229 ]\n",
            " [13.78   14.06    0.8759  5.479   3.156   3.136   4.872 ]\n",
            " [18.98   16.57    0.8687  6.449   3.552   2.144   6.453 ]\n",
            " [12.88   13.5     0.8879  5.139   3.119   2.352   4.607 ]\n",
            " [20.16   17.03    0.8735  6.513   3.773   1.91    6.185 ]\n",
            " [15.38   14.66    0.899   5.477   3.465   3.6     5.439 ]\n",
            " [19.06   16.45    0.8854  6.416   3.719   2.248   6.163 ]\n",
            " [18.55   16.22    0.8865  6.153   3.674   1.738   5.894 ]\n",
            " [18.94   16.49    0.875   6.445   3.639   5.064   6.362 ]\n",
            " [15.88   14.9     0.8988  5.618   3.507   0.7651  5.091 ]\n",
            " [18.14   16.12    0.8772  6.059   3.563   3.619   6.011 ]\n",
            " [14.33   14.28    0.8831  5.504   3.199   3.328   5.224 ]\n",
            " [18.81   16.29    0.8906  6.272   3.693   3.237   6.053 ]\n",
            " [19.11   16.26    0.9081  6.154   3.93    2.936   6.079 ]\n",
            " [16.84   15.67    0.8623  5.998   3.484   4.675   5.877 ]\n",
            " [14.99   14.56    0.8883  5.57    3.377   2.958   5.175 ]\n",
            " [13.16   13.82    0.8662  5.454   2.975   0.8551  5.056 ]\n",
            " [15.38   14.77    0.8857  5.662   3.419   1.999   5.222 ]\n",
            " [17.32   15.91    0.8599  6.064   3.403   3.824   5.922 ]\n",
            " [14.52   14.6     0.8557  5.741   3.113   1.481   5.487 ]\n",
            " [18.72   16.19    0.8977  6.006   3.857   5.324   5.879 ]\n",
            " [17.08   15.38    0.9079  5.832   3.683   2.956   5.484 ]\n",
            " [18.72   16.34    0.881   6.219   3.684   2.188   6.097 ]\n",
            " [16.16   15.33    0.8644  5.845   3.395   4.266   5.795 ]\n",
            " [13.5    13.85    0.8852  5.351   3.158   2.249   5.176 ]\n",
            " [17.63   15.98    0.8673  6.191   3.561   4.076   6.06  ]\n",
            " [17.98   15.85    0.8993  5.979   3.687   2.257   5.919 ]\n",
            " [20.71   17.23    0.8763  6.579   3.814   4.451   6.451 ]\n",
            " [12.78   13.57    0.8716  5.262   3.026   1.176   4.782 ]\n",
            " [19.14   16.61    0.8722  6.259   3.737   6.682   6.053 ]\n",
            " [13.8    14.04    0.8794  5.376   3.155   1.56    4.961 ]\n",
            " [14.01   14.29    0.8625  5.609   3.158   2.217   5.132 ]\n",
            " [17.99   15.86    0.8992  5.89    3.694   2.068   5.837 ]\n",
            " [20.03   16.9     0.8811  6.493   3.857   3.063   6.32  ]\n",
            " [14.92   14.43    0.9006  5.384   3.412   1.142   5.088 ]\n",
            " [19.13   16.31    0.9035  6.183   3.902   2.109   5.924 ]\n",
            " [16.44   15.25    0.888   5.884   3.505   1.969   5.533 ]\n",
            " [14.7    14.21    0.9153  5.205   3.466   1.767   4.649 ]\n",
            " [13.89   14.02    0.888   5.439   3.199   3.986   4.738 ]\n",
            " [14.46   14.35    0.8818  5.388   3.377   2.802   5.044 ]\n",
            " [14.03   14.16    0.8796  5.438   3.201   1.717   5.001 ]\n",
            " [16.17   15.38    0.8588  5.762   3.387   4.286   5.703 ]\n",
            " [19.94   16.92    0.8752  6.675   3.763   3.252   6.55  ]\n",
            " [15.01   14.76    0.8657  5.789   3.245   1.791   5.001 ]\n",
            " [13.45   14.02    0.8604  5.516   3.065   3.531   5.097 ]\n",
            " [15.11   14.54    0.8986  5.579   3.462   3.128   5.18  ]\n",
            " [18.75   16.18    0.8999  6.111   3.869   4.188   5.992 ]\n",
            " [14.34   14.37    0.8726  5.63    3.19    1.313   5.15  ]\n",
            " [15.78   14.91    0.8923  5.674   3.434   5.593   5.136 ]\n",
            " [20.97   17.25    0.8859  6.563   3.991   4.677   6.316 ]\n",
            " [14.11   14.1     0.8911  5.42    3.302   2.7     5.    ]\n",
            " [18.45   16.12    0.8921  6.107   3.769   2.235   5.794 ]\n",
            " [15.56   14.89    0.8823  5.776   3.408   4.972   5.847 ]\n",
            " [16.2    15.27    0.8734  5.826   3.464   2.823   5.527 ]\n",
            " [15.49   14.94    0.8724  5.757   3.371   3.412   5.228 ]\n",
            " [15.57   15.15    0.8527  5.92    3.231   2.64    5.879 ]\n",
            " [15.38   14.9     0.8706  5.884   3.268   4.462   5.795 ]\n",
            " [13.84   13.94    0.8955  5.324   3.379   2.259   4.805 ]\n",
            " [18.59   16.05    0.9066  6.037   3.86    6.001   5.877 ]\n",
            " [14.49   14.61    0.8538  5.715   3.113   4.116   5.396 ]\n",
            " [20.88   17.05    0.9031  6.45    4.032   5.016   6.321 ]\n",
            " [17.55   15.66    0.8991  5.791   3.69    5.366   5.661 ]\n",
            " [16.53   15.34    0.8823  5.875   3.467   5.532   5.88  ]\n",
            " [14.88   14.57    0.8811  5.554   3.333   1.018   4.956 ]\n",
            " [12.73   13.75    0.8458  5.412   2.882   3.533   5.067 ]\n",
            " [13.22   13.84    0.868   5.395   3.07    4.157   5.088 ]\n",
            " [19.51   16.71    0.878   6.366   3.801   2.962   6.185 ]\n",
            " [18.65   16.41    0.8698  6.285   3.594   4.391   6.102 ]\n",
            " [19.15   16.45    0.889   6.245   3.815   3.084   6.185 ]\n",
            " [15.05   14.68    0.8779  5.712   3.328   2.129   5.36  ]\n",
            " [12.08   13.23    0.8664  5.099   2.936   1.415   4.961 ]\n",
            " [14.29   14.09    0.905   5.291   3.337   2.699   4.825 ]\n",
            " [15.26   14.84    0.871   5.763   3.312   2.221   5.22  ]\n",
            " [14.37   14.39    0.8726  5.569   3.153   1.464   5.3   ]\n",
            " [18.85   16.17    0.9056  6.152   3.806   2.843   6.2   ]\n",
            " [18.95   16.42    0.8829  6.248   3.755   3.368   6.148 ]\n",
            " [17.63   15.86    0.88    6.033   3.573   3.747   5.929 ]\n",
            " [14.11   14.26    0.8722  5.52    3.168   2.688   5.219 ]\n",
            " [13.74   14.05    0.8744  5.482   3.114   2.932   4.825 ]\n",
            " [18.88   16.26    0.8969  6.084   3.764   1.649   6.109 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-giEfs42bkq",
        "outputId": "2da54db8-536a-4c74-c0aa-14cee31a01ac"
      },
      "source": [
        "y = shuffled_dataset.iloc[:, -1].values\n",
        "print(y)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1\n",
            " 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0\n",
            " 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaplTMk72LmY"
      },
      "source": [
        "Normalization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVWR8ttky2d1",
        "outputId": "f2b48c83-21ce-4b9c-879d-4e1f3174347e"
      },
      "source": [
        "sc_X = StandardScaler()\n",
        "X = sc_X.fit_transform(X)\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-9.27669545e-01 -9.45141858e-01  1.30405478e-02 -7.08250331e-01\n",
            "  -8.52122634e-01 -3.17251824e-01 -9.68330367e-01]\n",
            " [-1.16538840e+00 -1.24649144e+00  3.35218788e-01 -1.18445906e+00\n",
            "  -1.08288524e+00 -4.49012248e-01 -7.05557787e-01]\n",
            " [ 3.27652848e-01  3.05915481e-01  4.67880416e-01  5.41771144e-02\n",
            "   3.72694294e-01 -2.35197428e-01  3.60548113e-01]\n",
            " [ 1.34942689e+00  1.39260032e+00 -2.45965488e-01  1.37177018e+00\n",
            "   1.10403426e+00 -1.32873005e+00  1.34969919e+00]\n",
            " [-1.38225473e+00 -1.32867768e+00 -1.11774190e+00 -1.06849113e+00\n",
            "  -1.54441046e+00  1.71129627e-01 -1.36812008e+00]\n",
            " [ 2.23390190e-01  3.97233534e-01 -1.07352136e+00  7.67256505e-01\n",
            "   7.02431240e-03  4.25971644e-01  7.75353402e-01]\n",
            " [ 1.61216878e+00  1.52957740e+00  4.80514857e-01  1.12749730e+00\n",
            "   1.43065210e+00  1.59130186e+00  1.18828174e+00]\n",
            " [-1.49902891e+00 -1.41086393e+00 -1.60416787e+00 -1.06849113e+00\n",
            "  -1.79292404e+00 -5.14497967e-01 -1.28553441e+00]\n",
            " [-4.06356259e-01 -4.15497145e-01  2.72046584e-01 -3.13465893e-01\n",
            "  -2.41489267e-01 -1.41157343e+00 -7.91897349e-01]\n",
            " [ 1.06583246e+00  9.26878247e-01  1.20067798e+00  9.84387946e-01\n",
            "   1.09338367e+00  3.80999523e-01  7.73476455e-01]\n",
            " [-8.56770938e-01 -9.54273663e-01  7.96375877e-01 -1.06355633e+00\n",
            "  -5.78757697e-01  2.78424653e+00 -1.03777741e+00]\n",
            " [ 1.01161588e+00  8.99482831e-01  1.04906469e+00  8.48680796e-01\n",
            "   1.18923891e+00 -2.84834702e-02  9.36770844e-01]\n",
            " [-9.36010558e-01 -7.35110334e-01 -1.82527059e+00 -2.73987450e-01\n",
            "  -9.76379424e-01  6.02704188e-01 -4.78447199e-01]\n",
            " [-9.06817014e-01 -7.44242139e-01 -1.47782346e+00 -4.19564211e-01\n",
            "  -1.17874048e+00 -6.63547297e-02 -7.09311681e-01]\n",
            " [ 4.27744998e-01  4.97683394e-01 -2.08062166e-01  7.82060922e-01\n",
            "   4.01095846e-01  2.91844267e-01  7.82861190e-01]\n",
            " [-2.04953574e+00 -2.15054017e+00 -8.52418646e-01 -2.02337599e+00\n",
            "  -2.16924461e+00 -3.59856991e-01 -1.77729453e+00]\n",
            " [ 1.62885081e+00  1.54784101e+00  4.99466518e-01  1.20151939e+00\n",
            "   1.77857112e+00  2.16568263e+00  1.19015869e+00]\n",
            " [ 3.86039936e-01  4.70287978e-01 -3.47041015e-01  3.70004665e-01\n",
            "   4.72099726e-01  1.09108564e+00  4.45010728e-01]\n",
            " [-6.85780180e-01 -6.62055891e-01 -1.19621080e-01 -6.53967471e-01\n",
            "  -7.17215263e-01  3.39183341e-01 -6.28602959e-01]\n",
            " [-1.76177080e+00 -1.59350004e+00 -2.69072978e+00 -1.65079818e+00\n",
            "  -1.52310930e+00 -1.30506051e+00 -1.94246586e+00]\n",
            " [-1.32386764e+00 -1.52044560e+00  1.20699520e+00 -1.70261363e+00\n",
            "  -9.23126514e-01 -5.48424304e-01 -1.44695185e+00]\n",
            " [ 3.15469011e-02  3.19613189e-02  3.03632686e-01 -2.71520047e-01\n",
            "   2.27136340e-01  8.37032607e-01  1.20298896e-01]\n",
            " [ 1.81685127e-01  3.69838118e-01 -1.13669356e+00  2.44167125e-01\n",
            "  -8.17305375e-02  1.39168876e+00  4.52518517e-01]\n",
            " [ 1.08668499e+00  1.00906450e+00  7.83741436e-01  7.79593519e-01\n",
            "   1.29219454e+00 -1.95748200e-01  7.41568356e-01]\n",
            " [-6.14881573e-01 -4.97683394e-01 -8.96639189e-01 -3.70216156e-01\n",
            "  -7.20765457e-01 -8.10367182e-01 -3.80845954e-01]\n",
            " [-8.10567686e-02 -2.05465621e-01  1.36492571e+00 -4.19564211e-01\n",
            "   3.58493518e-01 -1.42104124e+00 -7.11188628e-01]\n",
            " [ 2.02537659e-01  2.69388259e-01 -2.01744946e-01  4.66233371e-01\n",
            "   8.86787743e-02  6.68978893e-01  5.38858079e-01]\n",
            " [-3.06264108e-01 -9.58839566e-02 -1.50309235e+00  9.76386512e-03\n",
            "  -6.21360025e-01 -3.40132377e-01  3.71809795e-01]\n",
            " [ 8.19772589e-01  6.16396864e-01  1.83240002e+00  3.72472067e-01\n",
            "   1.04368096e+00 -2.51766104e-01  7.65968667e-01]\n",
            " [-1.65750815e+00 -1.84919059e+00  6.63714248e-01 -1.85559260e+00\n",
            "  -1.48760736e+00  5.04149871e-02 -1.78104842e+00]\n",
            " [ 7.65556008e-01  9.54273663e-01 -1.14301078e+00  1.09295367e+00\n",
            "   1.80983818e-01 -2.39142351e-01  1.34969919e+00]\n",
            " [-6.39904611e-01 -6.34660475e-01  3.19922090e-02 -4.24499017e-01\n",
            "  -6.14259637e-01 -3.47953468e-02 -4.59677729e-01]\n",
            " [-2.68729552e-01 -4.24628951e-01  1.51653900e+00 -7.42793970e-01\n",
            "   1.88084206e-01 -1.22852901e+00 -9.53314791e-01]\n",
            " [-2.12877536e+00 -2.36057169e+00  1.39384956e-01 -2.28492068e+00\n",
            "  -2.06628898e+00 -6.99909342e-01 -1.59710761e+00]\n",
            " [ 2.02087840e+00  1.82179518e+00  1.08065079e+00  1.83810929e+00\n",
            "   2.03063489e+00  2.07021549e+00  1.27086741e+00]\n",
            " [-5.43982967e-01 -4.06365340e-01 -1.01034916e+00 -3.10998491e-01\n",
            "  -8.84074380e-01 -9.65008159e-01 -2.15674618e-01]\n",
            " [ 1.10336702e+00  1.31954588e+00 -1.43992014e+00  1.77889163e+00\n",
            "   7.41914469e-01  4.22026721e-01  1.77201226e+00]\n",
            " [-8.15065875e-01 -9.17746442e-01  8.40596419e-01 -1.09069776e+00\n",
            "  -5.29054981e-01 -5.47635319e-01 -1.12224002e+00]\n",
            " [ 1.57046372e+00  1.62089546e+00 -4.54433761e-01  1.85784852e+00\n",
            "   1.15018678e+00 -9.47650498e-01  1.68004186e+00]\n",
            " [-1.50736992e+00 -1.50218199e+00 -8.33466985e-01 -1.48548219e+00\n",
            "  -1.46275600e+00  7.46299381e-01 -1.20107180e+00]\n",
            " [-6.02042372e-02 -5.02249296e-02  1.96239939e-01  1.22312679e-02\n",
            "  -1.42083835e-01 -1.77766227e+00 -4.63431623e-01]\n",
            " [ 8.44795627e-01  1.19170060e+00 -2.31169656e+00  2.06757775e+00\n",
            "   8.51285803e-02  1.40194556e+00  1.67816491e+00]\n",
            " [ 1.30355132e+00  1.17343699e+00  1.05538191e+00  7.03104034e-01\n",
            "   1.53005754e+00  9.08830203e-01  8.54185176e-01]\n",
            " [-3.47969171e-01 -3.24179091e-01  1.30405478e-02  1.20796988e-01\n",
            "  -2.30838685e-01  1.22679099e+00 -4.86263342e-02]\n",
            " [-7.27485243e-01 -8.53823804e-01  1.10591968e+00 -1.17705685e+00\n",
            "  -4.54500907e-01  8.11785100e-01 -1.45070575e+00]\n",
            " [-8.93977812e-02 -1.96333816e-01  1.15014022e+00 -2.93726672e-01\n",
            "   8.51285803e-02 -6.99120358e-01 -2.08166830e-01]\n",
            " [-7.94213344e-01 -7.44242139e-01 -4.22847659e-01 -5.99684611e-01\n",
            "  -6.71062741e-01  6.46098340e-01 -7.69373985e-01]\n",
            " [ 1.04080942e+00  9.81669079e-01  6.25810926e-01  5.15581426e-01\n",
            "   1.15373697e+00 -4.75837723e-01  6.10182065e-01]\n",
            " [-4.35222120e-02 -3.19613189e-02  2.02557160e-01  1.08459975e-01\n",
            "   3.89760584e-02  4.83567518e-01  6.90890786e-01]\n",
            " [-9.77715620e-01 -1.26475505e+00  2.30619155e+00 -1.74949429e+00\n",
            "  -2.76991207e-01  1.63942992e+00 -1.45070575e+00]\n",
            " [ 1.23298039e-01  2.23729232e-01 -4.48116541e-01  5.55059870e-01\n",
            "   1.41247004e-02 -8.80586809e-01  6.06428171e-01]\n",
            " [ 1.24099372e+00  1.25562324e+00 -1.85455542e-02  1.26567186e+00\n",
            "   1.23894163e+00  2.53184022e-01  1.28400604e+00]\n",
            " [-9.98568152e-01 -9.54273663e-01 -5.68143728e-01 -5.99684611e-01\n",
            "  -1.10418641e+00 -8.14312105e-01 -1.01713099e+00]\n",
            " [ 1.27018727e+00  1.37433671e+00 -6.43950373e-01  1.17191055e+00\n",
            "   1.17148794e+00  4.11769922e-01  7.71599508e-01]\n",
            " [-6.44075117e-01 -6.34660475e-01  6.72332742e-03 -6.98380720e-01\n",
            "  -6.03609055e-01 -3.56701053e-01 -8.31313236e-01]\n",
            " [ 1.09502600e+00  8.99482831e-01  1.63656619e+00  5.50125065e-01\n",
            "   1.54780851e+00  9.29343802e-01  3.68055901e-01]\n",
            " [-4.48061322e-01 -3.33310897e-01 -7.70294781e-01 -2.81389658e-01\n",
            "  -7.77568561e-01  1.09424158e+00 -4.50292994e-01]\n",
            " [-1.43614363e-01 -2.96783675e-01  1.55444232e+00 -1.14744802e+00\n",
            "   4.29497398e-01  1.41937198e-01 -7.69373985e-01]\n",
            " [ 8.73989171e-01  6.89451307e-01  1.63656619e+00  3.74939470e-01\n",
            "   1.10048406e+00 -1.35785372e-01  6.58982687e-01]\n",
            " [ 8.07261071e-01  7.99032972e-01  3.28901567e-01  8.51148198e-01\n",
            "   6.74460784e-01 -5.62626026e-01  1.20705121e+00]\n",
            " [ 1.18677714e+00  1.29215046e+00 -6.37633153e-01  1.33475913e+00\n",
            "   7.80966603e-01  1.58505874e-01  1.26711352e+00]\n",
            " [-1.06529625e+00 -1.05472352e+00 -3.72309896e-01 -8.61229301e-01\n",
            "  -1.08288524e+00 -1.58597170e-02 -1.27990357e+00]\n",
            " [ 1.10336702e+00  1.23735963e+00 -8.27149764e-01  1.53215135e+00\n",
            "   3.22991578e-01 -7.98532414e-01  1.68754965e+00]\n",
            " [-1.44064182e+00 -1.56610462e+00  3.85756551e-01 -1.70014623e+00\n",
            "  -1.21424242e+00 -6.34423623e-01 -1.77729453e+00]\n",
            " [ 1.59548676e+00  1.65742268e+00 -5.23923186e-01  1.69006513e+00\n",
            "   1.10758445e+00 -9.83154804e-01  1.18452785e+00]\n",
            " [-3.98015246e-01 -5.06815199e-01  1.08696801e+00 -8.66164107e-01\n",
            "   1.41247004e-02  3.50229125e-01 -2.15674618e-01]\n",
            " [ 1.13673107e+00  1.12777797e+00  2.27826041e-01  1.45072706e+00\n",
            "   9.15873975e-01 -7.16478018e-01  1.14323501e+00]\n",
            " [ 9.24035247e-01  9.17746442e-01  2.97315466e-01  8.01800144e-01\n",
            "   7.56115245e-01 -1.11886015e+00  6.38336270e-01]\n",
            " [ 1.08668499e+00  1.16430519e+00 -4.29164880e-01  1.52228174e+00\n",
            "   6.31858456e-01  1.50530254e+00  1.51674747e+00]\n",
            " [-1.89489932e-01 -2.87651870e-01  1.07433357e+00 -5.18260321e-01\n",
            "   1.63232848e-01 -1.88646324e+00 -8.68852176e-01]\n",
            " [ 7.53044489e-01  8.26428388e-01 -2.90186031e-01  5.69864286e-01\n",
            "   3.62043712e-01  3.65219832e-01  8.57939070e-01]\n",
            " [-8.35918407e-01 -8.53823804e-01  8.25299721e-02 -7.99544233e-01\n",
            "  -9.30226902e-01  1.35625321e-01 -6.19218224e-01]\n",
            " [ 1.03246841e+00  9.81669079e-01  5.56321502e-01  1.09542107e+00\n",
            "   8.23568931e-01  6.38277249e-02  9.36770844e-01]\n",
            " [ 1.15758360e+00  9.54273663e-01  1.66183507e+00  8.04267546e-01\n",
            "   1.66496491e+00 -1.73656632e-01  9.85571466e-01]\n",
            " [ 2.10878671e-01  4.15497145e-01 -1.23145187e+00  4.19352719e-01\n",
            "   8.15783863e-02  1.19838754e+00  6.06428171e-01]\n",
            " [-5.60664992e-01 -5.98133253e-01  4.11025433e-01 -6.36695652e-01\n",
            "  -2.98292371e-01 -1.56298971e-01 -7.11188628e-01]\n",
            " [-1.32386764e+00 -1.27388685e+00 -9.85080274e-01 -9.22914369e-01\n",
            "  -1.72547036e+00 -1.81545463e+00 -9.34545321e-01]\n",
            " [-3.98015246e-01 -4.06365340e-01  2.46777702e-01 -4.09694600e-01\n",
            "  -1.49184223e-01 -9.12935177e-01 -6.22972118e-01]\n",
            " [ 4.11062973e-01  6.34660475e-01 -1.38306516e+00  5.82201300e-01\n",
            "  -2.05987327e-01  5.26961669e-01  6.90890786e-01]\n",
            " [-7.56678787e-01 -5.61606031e-01 -1.64838842e+00 -2.14769784e-01\n",
            "  -1.23554359e+00 -1.32162919e+00 -1.25581162e-01]\n",
            " [ 9.94933854e-01  8.90351026e-01  1.00484415e+00  4.39091941e-01\n",
            "   1.40580075e+00  1.71043853e+00  6.10182065e-01]\n",
            " [ 3.10970822e-01  1.50674789e-01  1.64920063e+00  9.76386512e-03\n",
            "   7.88066991e-01 -1.57876940e-01 -1.31212003e-01]\n",
            " [ 9.94933854e-01  1.02732811e+00 -5.01316561e-02  9.64648724e-01\n",
            "   7.91617185e-01 -7.63817093e-01  1.01935651e+00]\n",
            " [-7.27157561e-02  1.05015762e-01 -1.09879024e+00  4.18401007e-02\n",
            "  -2.34388879e-01  8.75692851e-01  4.52518517e-01]\n",
            " [-1.18207043e+00 -1.24649144e+00  2.15191600e-01 -1.17705685e+00\n",
            "  -1.07578486e+00 -7.15689034e-01 -7.09311681e-01]\n",
            " [ 5.40348668e-01  6.98583112e-01 -9.15590850e-01  8.95561448e-01\n",
            "   3.54943324e-01  7.25785782e-01  9.49909473e-01]\n",
            " [ 6.86316388e-01  5.79869642e-01  1.10591968e+00  3.72472067e-01\n",
            "   8.02267767e-01 -7.09377157e-01  6.85259945e-01]\n",
            " [ 1.82486460e+00  1.84005879e+00 -3.47041015e-01  1.85291371e+00\n",
            "   1.25314240e+00  1.02165500e+00  1.68379575e+00]\n",
            " [-1.48234688e+00 -1.50218199e+00 -6.43950373e-01 -1.39665569e+00\n",
            "  -1.54441046e+00 -1.56226948e+00 -1.44882880e+00]\n",
            " [ 1.17009512e+00  1.27388685e+00 -6.06047051e-01  1.06334483e+00\n",
            "   9.79777467e-01  2.78187958e+00  9.36770844e-01]\n",
            " [-1.05695524e+00 -1.07298713e+00 -1.51207182e-01 -1.11537178e+00\n",
            "  -1.08643544e+00 -1.25929940e+00 -1.11285529e+00]\n",
            " [-9.69374608e-01 -8.44691999e-01 -1.21881743e+00 -5.40466945e-01\n",
            "  -1.07578486e+00 -7.40936540e-01 -7.91897349e-01]\n",
            " [ 6.90486895e-01  5.89001448e-01  1.09960246e+00  1.52873224e-01\n",
            "   8.27119125e-01 -8.58495241e-01  5.31350291e-01]\n",
            " [ 1.54127018e+00  1.53870921e+00 -4.38144357e-02  1.64071707e+00\n",
            "   1.40580075e+00 -7.34555909e-02  1.43791569e+00]\n",
            " [-5.89858536e-01 -7.16846723e-01  1.18804354e+00 -1.09563256e+00\n",
            "  -1.74035581e-01 -1.58909496e+00 -8.74483017e-01]\n",
            " [ 1.16592461e+00  9.99932690e-01  1.37124293e+00  8.75822226e-01\n",
            "   1.56555948e+00 -8.26146874e-01  6.94644680e-01]\n",
            " [ 4.40584200e-02  3.19613189e-02  3.92073771e-01  1.38068807e-01\n",
            "   1.56132460e-01 -9.36604714e-01 -3.92415992e-02]\n",
            " [-6.81609674e-01 -9.17746442e-01  2.11667494e+00 -1.53729765e+00\n",
            "   1.76748944e-02 -1.09597960e+00 -1.69846275e+00]\n",
            " [-1.01942068e+00 -1.09125074e+00  3.92073771e-01 -9.59925411e-01\n",
            "  -9.30226902e-01  6.54777170e-01 -1.53141447e+00]\n",
            " [-7.81701825e-01 -7.89901166e-01  4.06107025e-04 -1.08576295e+00\n",
            "  -2.98292371e-01 -2.79380565e-01 -9.57068685e-01]\n",
            " [-9.61033595e-01 -9.63405469e-01 -1.38572742e-01 -9.62392813e-01\n",
            "  -9.23126514e-01 -1.13542883e+00 -1.03777741e+00]\n",
            " [-6.85452498e-02  1.50674789e-01 -1.45255458e+00 -1.62954326e-01\n",
            "  -2.62790431e-01  8.91472542e-01  2.79839392e-01]\n",
            " [ 1.50373562e+00  1.55697282e+00 -4.16530439e-01  2.08978437e+00\n",
            "   1.07208251e+00  7.56624935e-02  1.86961351e+00]\n",
            " [-5.52323979e-01 -4.15497145e-01 -1.01666638e+00 -9.63344526e-02\n",
            "  -7.66917979e-01 -1.07704397e+00 -1.03777741e+00]\n",
            " [-1.20292296e+00 -1.09125074e+00 -1.35147906e+00 -7.69935400e-01\n",
            "  -1.40595290e+00  2.95789189e-01 -8.57590494e-01]\n",
            " [-5.10618916e-01 -6.16396864e-01  1.06169913e+00 -6.14489027e-01\n",
            "   3.47411841e-03 -2.21715936e-02 -7.01803893e-01]\n",
            " [ 1.00744537e+00  8.81219220e-01  1.14382300e+00  6.98169229e-01\n",
            "   1.44840307e+00  8.14152054e-01  8.22277077e-01]\n",
            " [-8.31747900e-01 -7.71637555e-01 -5.80778169e-01 -4.88651488e-01\n",
            "  -9.62178648e-01 -1.45417859e+00 -7.58112303e-01]\n",
            " [-2.31194995e-01 -2.78520064e-01  6.63714248e-01 -3.80085767e-01\n",
            "  -9.59313135e-02  1.92267538e+00 -7.84389561e-01]\n",
            " [ 1.93329777e+00  1.85832240e+00  2.59412143e-01  1.81343527e+00\n",
            "   1.88152674e+00  1.19996551e+00  1.43040791e+00]\n",
            " [-9.27669545e-01 -1.01819630e+00  5.87907604e-01 -1.00680606e+00\n",
            "  -5.64556921e-01 -3.59856991e-01 -1.03965435e+00]\n",
            " [ 8.82330184e-01  8.26428388e-01  6.51079808e-01  6.88299618e-01\n",
            "   1.09338367e+00 -7.26734818e-01  4.50641570e-01]\n",
            " [-3.22946133e-01 -2.96783675e-01  3.19922090e-02 -1.28410688e-01\n",
            "  -1.88236357e-01  1.43271596e+00  5.50119761e-01]\n",
            " [-5.60337309e-02  5.02249296e-02 -5.30240406e-01 -5.04055131e-03\n",
            "   1.05745064e-02 -2.62811889e-01 -5.05032812e-02]\n",
            " [-3.52139677e-01 -2.51124648e-01 -5.93412610e-01 -1.75291340e-01\n",
            "  -3.19593535e-01  2.01900025e-01 -6.11710436e-01]\n",
            " [-3.18775627e-01 -5.93567350e-02 -1.83790503e+00  2.26895306e-01\n",
            "  -8.16620694e-01 -4.07196065e-01  6.10182065e-01]\n",
            " [-3.98015246e-01 -2.87651870e-01 -7.07122577e-01  1.38068807e-01\n",
            "  -6.85263517e-01  1.03033383e+00  4.52518517e-01]\n",
            " [-1.04027321e+00 -1.16430519e+00  8.65865301e-01 -1.24367673e+00\n",
            "  -2.91191983e-01 -7.07799188e-01 -1.40565902e+00]\n",
            " [ 9.40717272e-01  7.62505750e-01  1.56707676e+00  5.15581426e-01\n",
            "   1.41645133e+00  2.24458109e+00  6.06428171e-01]\n",
            " [-7.69190306e-01 -5.52474226e-01 -1.76841560e+00 -2.78922255e-01\n",
            "  -1.23554359e+00  7.57345165e-01 -2.96383339e-01]\n",
            " [ 1.89576321e+00  1.67568629e+00  1.34597405e+00  1.53461876e+00\n",
            "   2.02708470e+00  1.46743128e+00  1.43979264e+00]\n",
            " [ 5.06984618e-01  4.06365340e-01  1.09328524e+00 -9.13996471e-02\n",
            "   8.12918349e-01  1.74357588e+00  2.01007618e-01]\n",
            " [ 8.15929766e-02  1.14147567e-01  3.19922090e-02  1.15862183e-01\n",
            "   2.12250884e-02  1.87454732e+00  6.12059012e-01]\n",
            " [-6.06540561e-01 -5.89001448e-01 -4.38144357e-02 -6.76174096e-01\n",
            "  -4.54500907e-01 -1.68692904e+00 -1.12224002e+00]\n",
            " [-1.50319941e+00 -1.33780949e+00 -2.27379323e+00 -1.02654528e+00\n",
            "  -2.05563840e+00  2.97367159e-01 -9.13898904e-01]\n",
            " [-1.29884460e+00 -1.25562324e+00 -8.71370307e-01 -1.06849113e+00\n",
            "  -1.38820193e+00  7.89693532e-01 -8.74483017e-01]\n",
            " [ 1.32440385e+00  1.36520491e+00 -2.39648268e-01  1.32735693e+00\n",
            "   1.20698988e+00 -1.53143033e-01  1.18452785e+00]\n",
            " [ 9.65740310e-01  1.09125074e+00 -7.57660340e-01  1.12749730e+00\n",
            "   4.72099726e-01  9.74315923e-01  1.02874125e+00]\n",
            " [ 1.17426562e+00  1.12777797e+00  4.55245975e-01  1.02880120e+00\n",
            "   1.25669260e+00 -5.68869149e-02  1.18452785e+00]\n",
            " [-5.35641954e-01 -4.88551588e-01 -2.45965488e-01 -2.86324463e-01\n",
            "  -4.72251877e-01 -8.10367182e-01 -3.63953431e-01]\n",
            " [-1.77428232e+00 -1.81266337e+00 -9.72445834e-01 -1.79884234e+00\n",
            "  -1.86392792e+00 -1.37370217e+00 -1.11285529e+00]\n",
            " [-8.52600432e-01 -1.02732811e+00  1.46600124e+00 -1.32510102e+00\n",
            "  -4.40300131e-01 -3.60645976e-01 -1.36812008e+00]\n",
            " [-4.48061322e-01 -3.42442702e-01 -6.81853695e-01 -1.60486924e-01\n",
            "  -5.29054981e-01 -7.37780602e-01 -6.26726012e-01]\n",
            " [-8.19236381e-01 -7.53373945e-01 -5.80778169e-01 -6.39163055e-01\n",
            "  -1.09353583e+00 -1.33504192e+00 -4.76570252e-01]\n",
            " [ 1.04915044e+00  8.72087415e-01  1.50390456e+00  7.99332741e-01\n",
            "   1.22474085e+00 -2.47032197e-01  1.21268205e+00]\n",
            " [ 1.09085550e+00  1.10038255e+00  6.98955313e-02  1.03620340e+00\n",
            "   1.04368096e+00  1.67184704e-01  1.11508081e+00]\n",
            " [ 5.40348668e-01  5.89001448e-01 -1.13303860e-01  5.05711815e-01\n",
            "   3.97545652e-01  4.66209857e-01  7.04029415e-01]\n",
            " [-9.27669545e-01 -8.72087415e-01 -6.06047051e-01 -7.60065789e-01\n",
            "  -1.04028292e+00 -3.69324806e-01 -6.28602959e-01]\n",
            " [-1.08197828e+00 -1.06385533e+00 -4.67068202e-01 -8.53827093e-01\n",
            "  -1.23199339e+00 -1.76812570e-01 -1.36812008e+00]\n",
            " [ 1.06166195e+00  9.54273663e-01  9.54306386e-01  6.31549355e-01\n",
            "   1.07563270e+00 -1.18907978e+00  1.04187988e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75F437lvy2d2"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNShp8KWy2d2"
      },
      "source": [
        "architecture = np.array([7, 2, 1])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIgkvjUQy2d2"
      },
      "source": [
        "classifier = NeuralNetwork(architecture)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CeDWHu62yQx"
      },
      "source": [
        "Training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mA7V-jzy2d2",
        "outputId": "d125d264-3cd5-4438-dc4d-750cd1b5532c"
      },
      "source": [
        "classifier.fit(X_train, y_train, 10)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:  0\n",
            "Cost:  [[0.58094787]]\n",
            "Accuracy: 84.6938775510204\n",
            "Iteration:  1\n",
            "Cost:  [[0.56044304]]\n",
            "Accuracy: 86.73469387755102\n",
            "Iteration:  2\n",
            "Cost:  [[0.53968355]]\n",
            "Accuracy: 86.73469387755102\n",
            "Iteration:  3\n",
            "Cost:  [[0.51912502]]\n",
            "Accuracy: 86.73469387755102\n",
            "Iteration:  4\n",
            "Cost:  [[0.49911184]]\n",
            "Accuracy: 88.77551020408163\n",
            "Iteration:  5\n",
            "Cost:  [[0.47987608]]\n",
            "Accuracy: 88.77551020408163\n",
            "Iteration:  6\n",
            "Cost:  [[0.4615548]]\n",
            "Accuracy: 89.79591836734694\n",
            "Iteration:  7\n",
            "Cost:  [[0.44421334]]\n",
            "Accuracy: 90.81632653061224\n",
            "Iteration:  8\n",
            "Cost:  [[0.42786712]]\n",
            "Accuracy: 90.81632653061224\n",
            "Iteration:  9\n",
            "Cost:  [[0.41249922]]\n",
            "Accuracy: 90.81632653061224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Trgf0XBQ20qx"
      },
      "source": [
        "Testing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr17DFXCy2d3",
        "outputId": "3741d400-d8a6-4209-dbc3-d7f681624210"
      },
      "source": [
        "acc = 0\n",
        "n_c = 0\n",
        "for i in range(0, X_test.shape[0]):\n",
        "  x = X_test[i].reshape((X_test[i].size, 1))\n",
        "  y = y_test[i]\n",
        "  y_pred = classifier.predict(x)\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  #print('Expected: %d Got: %d' %(y, y_pred))\n",
        "  if y_pred == y:\n",
        "      n_c += 1\n",
        "\n",
        "acc = (n_c/X_test.shape[0])*100\n",
        "print(\"Test Accuracy\", acc)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy 95.23809523809523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgldFqo_3Wsl"
      },
      "source": [
        "## Questionnaire: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "1VUFJooq6FIS"
      },
      "source": [
        "#@markdown 1. What is the objective of backpropagation algorithm?\n",
        "#@markdown - A) to develop learning algorithm for multilayer feedforward neural network\n",
        "#@markdown - B) to develop learning algorithm for single layer feedforward neural network\n",
        "#@markdown - C) to develop learning algorithm for multilayer feedforward neural network, so that network can be trained to capture the mapping implicitly\n",
        "Ans = \"\" #@param [\"A\", \"B\", \"C\"] {allow-input: true}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ZmCa838-6vxu"
      },
      "source": [
        "#@markdown 2. The backpropagation law is also known as generalized delta rule, is it true?\n",
        "#@markdown - A) Yes\n",
        "#@markdown - B) No\n",
        "Ans = \"\" #@param [\"A\", \"B\"] {allow-input: true}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Rd_350Bf7Fvg"
      },
      "source": [
        "#@markdown 3. There is feedback in final stage of backpropagation algorithm?\n",
        "#@markdown - A) Yes\n",
        "#@markdown - B) No\n",
        "Ans = \"\" #@param [\"A\", \"B\"] {allow-input: true}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ybNnEUhx7bFq"
      },
      "source": [
        "#@markdown 4. What are the general tasks that are performed with backpropagation algorithm?\n",
        "#@markdown - A) Pattern mapping\n",
        "#@markdown - B) Function approximation\n",
        "#@markdown - C) Prediction\n",
        "#@markdown - D) All the above \n",
        "Ans = \"\" #@param [\"A\", \"B\", \"C\", \"D\"] {allow-input: true}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "yIJyhVcl74Sh"
      },
      "source": [
        "#@markdown 5. Does backpropagaion learning is based on gradient descent along error surface?\n",
        "#@markdown - A) Yes\n",
        "#@markdown - B) No\n",
        "#@markdown - C) it depends on gradient descent but not error surface\n",
        "Ans = \"\" #@param [\"A\", \"B\", \"C\"] {allow-input: true}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}